{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv3 Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![YOLOv3 ]( https://d33wubrfki0l68.cloudfront.net/c6fd049f28b66dbd35faed6965905ec6281f7d7d/c0399/assets/images/yolo/yolo-architecture.webp )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNBlock\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, input, output, kernel, stride=1):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=input,\n",
    "                              out_channels=output,\n",
    "                              kernel_size=kernel,\n",
    "                              stride=stride,\n",
    "                              padding=kernel//2\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(output)\n",
    "        self.act = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.act(self.bn(self.conv(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Block\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.cnnblock1 = CNNBlock(input=input,\n",
    "                                   output=input//2,\n",
    "                                   kernel=1)\n",
    "        self.cnnblock2 = CNNBlock(input=input//2,\n",
    "                                   output=input,\n",
    "                                   kernel=3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        residual = self.cnnblock1(x)\n",
    "        residual = self.cnnblock2(residual)\n",
    "        return x + residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Backbone - Darknet53\n",
    "\n",
    "class Darknet53(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Darknet53, self).__init__()\n",
    "        self.c1 = CNNBlock(3, 32, 3)\n",
    "        self.c2 = CNNBlock(32, 64, 3, stride=2)\n",
    "        self.r1 = self._make_resblocks(64, 1)\n",
    "        self.c3 = CNNBlock(64, 128, 3, stride=2)\n",
    "        self.r2 = self._make_resblocks(128, 2)\n",
    "        self.c4 = CNNBlock(128, 256, 3, stride=2)\n",
    "        self.r3 = self._make_resblocks(256, 8)\n",
    "        self.c5 = CNNBlock(256, 512, 3, stride=2)\n",
    "        self.r4 = self._make_resblocks(512, 8)\n",
    "        self.c6 = CNNBlock(512, 1024, 3, stride=2)\n",
    "        self.r5 = self._make_resblocks(1024, 4)\n",
    "\n",
    "    def _make_resblocks(self, input, num_blocks=1):\n",
    "        block_layes = []\n",
    "        for _ in range(num_blocks):\n",
    "            block_layes.append(ResidualBlock(input=input))\n",
    "        return nn.Sequential(*block_layes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.c1(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.r1(x)\n",
    "        x = self.c3(x)\n",
    "        x = self.r2(x)\n",
    "        x = self.c4(x)\n",
    "        x = self.r3(x)\n",
    "        route1 = x\n",
    "        x = self.c5(x)\n",
    "        x = self.r4(x)\n",
    "        route2 = x\n",
    "        x = self.c6(x)\n",
    "        route3 = self.r5(x)\n",
    "        return route1, route2, route3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO v3\n",
    "\n",
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self, num_classes:int=20, anchors_per_scale:int=3):\n",
    "        super(YOLOv3, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors_per_scale = anchors_per_scale\n",
    "        self.darknet = Darknet53()\n",
    "        self.layer1 =  nn.Sequential(\n",
    "            CNNBlock(1024, 512, 1),\n",
    "            CNNBlock(512, 1024, 3),\n",
    "            CNNBlock(1024, 512, 1),\n",
    "            CNNBlock(512, 1024, 3),\n",
    "            CNNBlock(1024, 512, 1)\n",
    "        )\n",
    "        self.pred1 = nn.Sequential(\n",
    "            CNNBlock(512, 1024, 3),\n",
    "            nn.Conv2d(1024, 3*(self.num_classes + 5), 1)\n",
    "        )\n",
    "\n",
    "        self.presampling1 = CNNBlock(512, 256, 1)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2,  mode='nearest')\n",
    "        self.layer2 = nn.Sequential(\n",
    "            CNNBlock(768, 256, 1),\n",
    "            CNNBlock(256, 512, 3)\n",
    "        )\n",
    "        self.pred2 = nn.Conv2d(512, 3*(self.num_classes + 5), 1)\n",
    "\n",
    "        self.presampling2 = CNNBlock(512, 128, 1)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.layer3 = nn.Sequential(\n",
    "            CNNBlock(384, 128, 1),\n",
    "            CNNBlock(128, 256, 3)\n",
    "        )\n",
    "        self.pred3 = nn.Conv2d(256, 3*(self.num_classes + 5), 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        route1, route2, route3 = self.darknet(x)\n",
    "        \n",
    "        x = self.layer1(route3)\n",
    "        output1 = self.pred1(x)\n",
    "        output1 = output1.reshape(\n",
    "            output1.shape[0], self.anchors_per_scale, self.num_classes + 5, output1.shape[2], output1.shape[3]\n",
    "        ).permute(0, 1, 3, 4, 2)    # [batch, anchors, grid, grid, classes + 5]\n",
    "\n",
    "        x = self.upsample1(self.presampling1(x))\n",
    "        x = torch.cat([x, route2], 1)\n",
    "        route2 = self.layer2(x)\n",
    "        output2 = self.pred2(route2)\n",
    "        output2 = output2.reshape(\n",
    "            output2.shape[0], self.anchors_per_scale, self.num_classes + 5, output2.shape[2], output2.shape[3]\n",
    "        ).permute(0, 1, 3, 4, 2)\n",
    "\n",
    "        x = self.upsample2(self.presampling2(route2))\n",
    "        route1 = torch.cat([x, route1], 1)\n",
    "        route1 = self.layer3(route1)\n",
    "        output3 = self.pred3(route1)\n",
    "        output3 = output3.reshape(\n",
    "            output3.shape[0], self.anchors_per_scale, self.num_classes + 5, output3.shape[2], output3.shape[3]\n",
    "        ).permute(0, 1, 3, 4, 2)\n",
    "\n",
    "        return output1, output2, output3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [32, 32, 416, 416]             896\n",
      "       BatchNorm2d-2         [32, 32, 416, 416]              64\n",
      "         LeakyReLU-3         [32, 32, 416, 416]               0\n",
      "          CNNBlock-4         [32, 32, 416, 416]               0\n",
      "            Conv2d-5         [32, 64, 208, 208]          18,496\n",
      "       BatchNorm2d-6         [32, 64, 208, 208]             128\n",
      "         LeakyReLU-7         [32, 64, 208, 208]               0\n",
      "          CNNBlock-8         [32, 64, 208, 208]               0\n",
      "            Conv2d-9         [32, 32, 208, 208]           2,080\n",
      "      BatchNorm2d-10         [32, 32, 208, 208]              64\n",
      "        LeakyReLU-11         [32, 32, 208, 208]               0\n",
      "         CNNBlock-12         [32, 32, 208, 208]               0\n",
      "           Conv2d-13         [32, 64, 208, 208]          18,496\n",
      "      BatchNorm2d-14         [32, 64, 208, 208]             128\n",
      "        LeakyReLU-15         [32, 64, 208, 208]               0\n",
      "         CNNBlock-16         [32, 64, 208, 208]               0\n",
      "    ResidualBlock-17         [32, 64, 208, 208]               0\n",
      "           Conv2d-18        [32, 128, 104, 104]          73,856\n",
      "      BatchNorm2d-19        [32, 128, 104, 104]             256\n",
      "        LeakyReLU-20        [32, 128, 104, 104]               0\n",
      "         CNNBlock-21        [32, 128, 104, 104]               0\n",
      "           Conv2d-22         [32, 64, 104, 104]           8,256\n",
      "      BatchNorm2d-23         [32, 64, 104, 104]             128\n",
      "        LeakyReLU-24         [32, 64, 104, 104]               0\n",
      "         CNNBlock-25         [32, 64, 104, 104]               0\n",
      "           Conv2d-26        [32, 128, 104, 104]          73,856\n",
      "      BatchNorm2d-27        [32, 128, 104, 104]             256\n",
      "        LeakyReLU-28        [32, 128, 104, 104]               0\n",
      "         CNNBlock-29        [32, 128, 104, 104]               0\n",
      "    ResidualBlock-30        [32, 128, 104, 104]               0\n",
      "           Conv2d-31         [32, 64, 104, 104]           8,256\n",
      "      BatchNorm2d-32         [32, 64, 104, 104]             128\n",
      "        LeakyReLU-33         [32, 64, 104, 104]               0\n",
      "         CNNBlock-34         [32, 64, 104, 104]               0\n",
      "           Conv2d-35        [32, 128, 104, 104]          73,856\n",
      "      BatchNorm2d-36        [32, 128, 104, 104]             256\n",
      "        LeakyReLU-37        [32, 128, 104, 104]               0\n",
      "         CNNBlock-38        [32, 128, 104, 104]               0\n",
      "    ResidualBlock-39        [32, 128, 104, 104]               0\n",
      "           Conv2d-40          [32, 256, 52, 52]         295,168\n",
      "      BatchNorm2d-41          [32, 256, 52, 52]             512\n",
      "        LeakyReLU-42          [32, 256, 52, 52]               0\n",
      "         CNNBlock-43          [32, 256, 52, 52]               0\n",
      "           Conv2d-44          [32, 128, 52, 52]          32,896\n",
      "      BatchNorm2d-45          [32, 128, 52, 52]             256\n",
      "        LeakyReLU-46          [32, 128, 52, 52]               0\n",
      "         CNNBlock-47          [32, 128, 52, 52]               0\n",
      "           Conv2d-48          [32, 256, 52, 52]         295,168\n",
      "      BatchNorm2d-49          [32, 256, 52, 52]             512\n",
      "        LeakyReLU-50          [32, 256, 52, 52]               0\n",
      "         CNNBlock-51          [32, 256, 52, 52]               0\n",
      "    ResidualBlock-52          [32, 256, 52, 52]               0\n",
      "           Conv2d-53          [32, 128, 52, 52]          32,896\n",
      "      BatchNorm2d-54          [32, 128, 52, 52]             256\n",
      "        LeakyReLU-55          [32, 128, 52, 52]               0\n",
      "         CNNBlock-56          [32, 128, 52, 52]               0\n",
      "           Conv2d-57          [32, 256, 52, 52]         295,168\n",
      "      BatchNorm2d-58          [32, 256, 52, 52]             512\n",
      "        LeakyReLU-59          [32, 256, 52, 52]               0\n",
      "         CNNBlock-60          [32, 256, 52, 52]               0\n",
      "    ResidualBlock-61          [32, 256, 52, 52]               0\n",
      "           Conv2d-62          [32, 128, 52, 52]          32,896\n",
      "      BatchNorm2d-63          [32, 128, 52, 52]             256\n",
      "        LeakyReLU-64          [32, 128, 52, 52]               0\n",
      "         CNNBlock-65          [32, 128, 52, 52]               0\n",
      "           Conv2d-66          [32, 256, 52, 52]         295,168\n",
      "      BatchNorm2d-67          [32, 256, 52, 52]             512\n",
      "        LeakyReLU-68          [32, 256, 52, 52]               0\n",
      "         CNNBlock-69          [32, 256, 52, 52]               0\n",
      "    ResidualBlock-70          [32, 256, 52, 52]               0\n",
      "           Conv2d-71          [32, 128, 52, 52]          32,896\n",
      "      BatchNorm2d-72          [32, 128, 52, 52]             256\n",
      "        LeakyReLU-73          [32, 128, 52, 52]               0\n",
      "         CNNBlock-74          [32, 128, 52, 52]               0\n",
      "           Conv2d-75          [32, 256, 52, 52]         295,168\n",
      "      BatchNorm2d-76          [32, 256, 52, 52]             512\n",
      "        LeakyReLU-77          [32, 256, 52, 52]               0\n",
      "         CNNBlock-78          [32, 256, 52, 52]               0\n",
      "    ResidualBlock-79          [32, 256, 52, 52]               0\n",
      "           Conv2d-80          [32, 128, 52, 52]          32,896\n",
      "      BatchNorm2d-81          [32, 128, 52, 52]             256\n",
      "        LeakyReLU-82          [32, 128, 52, 52]               0\n",
      "         CNNBlock-83          [32, 128, 52, 52]               0\n",
      "           Conv2d-84          [32, 256, 52, 52]         295,168\n",
      "      BatchNorm2d-85          [32, 256, 52, 52]             512\n",
      "        LeakyReLU-86          [32, 256, 52, 52]               0\n",
      "         CNNBlock-87          [32, 256, 52, 52]               0\n",
      "    ResidualBlock-88          [32, 256, 52, 52]               0\n",
      "           Conv2d-89          [32, 128, 52, 52]          32,896\n",
      "      BatchNorm2d-90          [32, 128, 52, 52]             256\n",
      "        LeakyReLU-91          [32, 128, 52, 52]               0\n",
      "         CNNBlock-92          [32, 128, 52, 52]               0\n",
      "           Conv2d-93          [32, 256, 52, 52]         295,168\n",
      "      BatchNorm2d-94          [32, 256, 52, 52]             512\n",
      "        LeakyReLU-95          [32, 256, 52, 52]               0\n",
      "         CNNBlock-96          [32, 256, 52, 52]               0\n",
      "    ResidualBlock-97          [32, 256, 52, 52]               0\n",
      "           Conv2d-98          [32, 128, 52, 52]          32,896\n",
      "      BatchNorm2d-99          [32, 128, 52, 52]             256\n",
      "       LeakyReLU-100          [32, 128, 52, 52]               0\n",
      "        CNNBlock-101          [32, 128, 52, 52]               0\n",
      "          Conv2d-102          [32, 256, 52, 52]         295,168\n",
      "     BatchNorm2d-103          [32, 256, 52, 52]             512\n",
      "       LeakyReLU-104          [32, 256, 52, 52]               0\n",
      "        CNNBlock-105          [32, 256, 52, 52]               0\n",
      "   ResidualBlock-106          [32, 256, 52, 52]               0\n",
      "          Conv2d-107          [32, 128, 52, 52]          32,896\n",
      "     BatchNorm2d-108          [32, 128, 52, 52]             256\n",
      "       LeakyReLU-109          [32, 128, 52, 52]               0\n",
      "        CNNBlock-110          [32, 128, 52, 52]               0\n",
      "          Conv2d-111          [32, 256, 52, 52]         295,168\n",
      "     BatchNorm2d-112          [32, 256, 52, 52]             512\n",
      "       LeakyReLU-113          [32, 256, 52, 52]               0\n",
      "        CNNBlock-114          [32, 256, 52, 52]               0\n",
      "   ResidualBlock-115          [32, 256, 52, 52]               0\n",
      "          Conv2d-116          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-117          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-118          [32, 512, 26, 26]               0\n",
      "        CNNBlock-119          [32, 512, 26, 26]               0\n",
      "          Conv2d-120          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-121          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-122          [32, 256, 26, 26]               0\n",
      "        CNNBlock-123          [32, 256, 26, 26]               0\n",
      "          Conv2d-124          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-125          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-126          [32, 512, 26, 26]               0\n",
      "        CNNBlock-127          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-128          [32, 512, 26, 26]               0\n",
      "          Conv2d-129          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-130          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-131          [32, 256, 26, 26]               0\n",
      "        CNNBlock-132          [32, 256, 26, 26]               0\n",
      "          Conv2d-133          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-134          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-135          [32, 512, 26, 26]               0\n",
      "        CNNBlock-136          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-137          [32, 512, 26, 26]               0\n",
      "          Conv2d-138          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-139          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-140          [32, 256, 26, 26]               0\n",
      "        CNNBlock-141          [32, 256, 26, 26]               0\n",
      "          Conv2d-142          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-143          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-144          [32, 512, 26, 26]               0\n",
      "        CNNBlock-145          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-146          [32, 512, 26, 26]               0\n",
      "          Conv2d-147          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-148          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-149          [32, 256, 26, 26]               0\n",
      "        CNNBlock-150          [32, 256, 26, 26]               0\n",
      "          Conv2d-151          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-152          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-153          [32, 512, 26, 26]               0\n",
      "        CNNBlock-154          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-155          [32, 512, 26, 26]               0\n",
      "          Conv2d-156          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-157          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-158          [32, 256, 26, 26]               0\n",
      "        CNNBlock-159          [32, 256, 26, 26]               0\n",
      "          Conv2d-160          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-161          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-162          [32, 512, 26, 26]               0\n",
      "        CNNBlock-163          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-164          [32, 512, 26, 26]               0\n",
      "          Conv2d-165          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-166          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-167          [32, 256, 26, 26]               0\n",
      "        CNNBlock-168          [32, 256, 26, 26]               0\n",
      "          Conv2d-169          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-170          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-171          [32, 512, 26, 26]               0\n",
      "        CNNBlock-172          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-173          [32, 512, 26, 26]               0\n",
      "          Conv2d-174          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-175          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-176          [32, 256, 26, 26]               0\n",
      "        CNNBlock-177          [32, 256, 26, 26]               0\n",
      "          Conv2d-178          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-179          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-180          [32, 512, 26, 26]               0\n",
      "        CNNBlock-181          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-182          [32, 512, 26, 26]               0\n",
      "          Conv2d-183          [32, 256, 26, 26]         131,328\n",
      "     BatchNorm2d-184          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-185          [32, 256, 26, 26]               0\n",
      "        CNNBlock-186          [32, 256, 26, 26]               0\n",
      "          Conv2d-187          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-188          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-189          [32, 512, 26, 26]               0\n",
      "        CNNBlock-190          [32, 512, 26, 26]               0\n",
      "   ResidualBlock-191          [32, 512, 26, 26]               0\n",
      "          Conv2d-192         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-193         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-194         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-195         [32, 1024, 13, 13]               0\n",
      "          Conv2d-196          [32, 512, 13, 13]         524,800\n",
      "     BatchNorm2d-197          [32, 512, 13, 13]           1,024\n",
      "       LeakyReLU-198          [32, 512, 13, 13]               0\n",
      "        CNNBlock-199          [32, 512, 13, 13]               0\n",
      "          Conv2d-200         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-201         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-202         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-203         [32, 1024, 13, 13]               0\n",
      "   ResidualBlock-204         [32, 1024, 13, 13]               0\n",
      "          Conv2d-205          [32, 512, 13, 13]         524,800\n",
      "     BatchNorm2d-206          [32, 512, 13, 13]           1,024\n",
      "       LeakyReLU-207          [32, 512, 13, 13]               0\n",
      "        CNNBlock-208          [32, 512, 13, 13]               0\n",
      "          Conv2d-209         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-210         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-211         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-212         [32, 1024, 13, 13]               0\n",
      "   ResidualBlock-213         [32, 1024, 13, 13]               0\n",
      "          Conv2d-214          [32, 512, 13, 13]         524,800\n",
      "     BatchNorm2d-215          [32, 512, 13, 13]           1,024\n",
      "       LeakyReLU-216          [32, 512, 13, 13]               0\n",
      "        CNNBlock-217          [32, 512, 13, 13]               0\n",
      "          Conv2d-218         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-219         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-220         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-221         [32, 1024, 13, 13]               0\n",
      "   ResidualBlock-222         [32, 1024, 13, 13]               0\n",
      "          Conv2d-223          [32, 512, 13, 13]         524,800\n",
      "     BatchNorm2d-224          [32, 512, 13, 13]           1,024\n",
      "       LeakyReLU-225          [32, 512, 13, 13]               0\n",
      "        CNNBlock-226          [32, 512, 13, 13]               0\n",
      "          Conv2d-227         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-228         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-229         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-230         [32, 1024, 13, 13]               0\n",
      "   ResidualBlock-231         [32, 1024, 13, 13]               0\n",
      "       Darknet53-232  [[-1, 256, 52, 52], [-1, 512, 26, 26], [-1, 1024, 13, 13]]               0\n",
      "          Conv2d-233          [32, 512, 13, 13]         524,800\n",
      "     BatchNorm2d-234          [32, 512, 13, 13]           1,024\n",
      "       LeakyReLU-235          [32, 512, 13, 13]               0\n",
      "        CNNBlock-236          [32, 512, 13, 13]               0\n",
      "          Conv2d-237         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-238         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-239         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-240         [32, 1024, 13, 13]               0\n",
      "          Conv2d-241          [32, 512, 13, 13]         524,800\n",
      "     BatchNorm2d-242          [32, 512, 13, 13]           1,024\n",
      "       LeakyReLU-243          [32, 512, 13, 13]               0\n",
      "        CNNBlock-244          [32, 512, 13, 13]               0\n",
      "          Conv2d-245         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-246         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-247         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-248         [32, 1024, 13, 13]               0\n",
      "          Conv2d-249          [32, 512, 13, 13]         524,800\n",
      "     BatchNorm2d-250          [32, 512, 13, 13]           1,024\n",
      "       LeakyReLU-251          [32, 512, 13, 13]               0\n",
      "        CNNBlock-252          [32, 512, 13, 13]               0\n",
      "          Conv2d-253         [32, 1024, 13, 13]       4,719,616\n",
      "     BatchNorm2d-254         [32, 1024, 13, 13]           2,048\n",
      "       LeakyReLU-255         [32, 1024, 13, 13]               0\n",
      "        CNNBlock-256         [32, 1024, 13, 13]               0\n",
      "          Conv2d-257           [32, 75, 13, 13]          76,875\n",
      "          Conv2d-258          [32, 256, 13, 13]         131,328\n",
      "     BatchNorm2d-259          [32, 256, 13, 13]             512\n",
      "       LeakyReLU-260          [32, 256, 13, 13]               0\n",
      "        CNNBlock-261          [32, 256, 13, 13]               0\n",
      "        Upsample-262          [32, 256, 26, 26]               0\n",
      "          Conv2d-263          [32, 256, 26, 26]         196,864\n",
      "     BatchNorm2d-264          [32, 256, 26, 26]             512\n",
      "       LeakyReLU-265          [32, 256, 26, 26]               0\n",
      "        CNNBlock-266          [32, 256, 26, 26]               0\n",
      "          Conv2d-267          [32, 512, 26, 26]       1,180,160\n",
      "     BatchNorm2d-268          [32, 512, 26, 26]           1,024\n",
      "       LeakyReLU-269          [32, 512, 26, 26]               0\n",
      "        CNNBlock-270          [32, 512, 26, 26]               0\n",
      "          Conv2d-271           [32, 75, 26, 26]          38,475\n",
      "          Conv2d-272          [32, 128, 26, 26]          65,664\n",
      "     BatchNorm2d-273          [32, 128, 26, 26]             256\n",
      "       LeakyReLU-274          [32, 128, 26, 26]               0\n",
      "        CNNBlock-275          [32, 128, 26, 26]               0\n",
      "        Upsample-276          [32, 128, 52, 52]               0\n",
      "          Conv2d-277          [32, 128, 52, 52]          49,280\n",
      "     BatchNorm2d-278          [32, 128, 52, 52]             256\n",
      "       LeakyReLU-279          [32, 128, 52, 52]               0\n",
      "        CNNBlock-280          [32, 128, 52, 52]               0\n",
      "          Conv2d-281          [32, 256, 52, 52]         295,168\n",
      "     BatchNorm2d-282          [32, 256, 52, 52]             512\n",
      "       LeakyReLU-283          [32, 256, 52, 52]               0\n",
      "        CNNBlock-284          [32, 256, 52, 52]               0\n",
      "          Conv2d-285           [32, 75, 52, 52]          19,275\n",
      "================================================================\n",
      "Total params: 58,401,409\n",
      "Trainable params: 58,401,409\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 63.38\n",
      "Forward/backward pass size (MB): 316329716534.02\n",
      "Params size (MB): 222.78\n",
      "Estimated Total Size (MB): 316329716820.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample = torch.rand(3, 416, 416)\n",
    "summary(YOLOv3(), (sample.shape), 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model.py ends here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    num_classes = 20\n",
    "    model = YOLOv3(num_classes=num_classes)\n",
    "    img_size = 416\n",
    "    x = torch.randn((2, 3, img_size, img_size))\n",
    "    out = model(x)\n",
    "    assert out[0].shape == (2, 3, img_size//32, img_size//32, 5 + num_classes)\n",
    "    assert out[1].shape == (2, 3, img_size//16, img_size//16, 5 + num_classes)\n",
    "    assert out[2].shape == (2, 3, img_size//8, img_size//8, 5 + num_classes)\n",
    "    print('Success!')\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
