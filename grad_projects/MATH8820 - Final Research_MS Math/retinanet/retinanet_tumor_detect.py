# -*- coding: utf-8 -*-
"""Copy of Detectron2_Obj_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_dCPlTXYDMbOr_Z0Fa8Sn4nARXq5gqFl
"""

!nvidia-smi

!pip install pyyaml
!pip install 'git+https://github.com/facebookresearch/detectron2.git'
!pip install tensorboard

import os
import cv2
import random
import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# Import detectron2 utilities
from detectron2 import model_zoo
from detectron2.config import get_cfg
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.engine import DefaultTrainer
from detectron2.engine import DefaultPredictor
from detectron2.evaluation import COCOEvaluator
from detectron2.utils.visualizer import Visualizer
from detectron2.utils.visualizer import ColorMode
from detectron2.evaluation import inference_on_dataset
from detectron2.data import build_detection_test_loader
from detectron2.data.datasets import register_coco_instances

# # Download and unzip the dataset
# !curl -L "https://universe.roboflow.com/ds/jKDai2wt3U?key=lBM8Mf5pSR" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip

# Register datasets
register_coco_instances("brain_tumor_train", {}, "/content/train/_annotations.coco.json", "/content/train")
register_coco_instances("brain_tumor_val", {}, "/content/valid/_annotations.coco.json", "/content/valid")
register_coco_instances("brain_tumor_test", {}, "/content/test/_annotations.coco.json", "/content/test")

# Visualize training data (same as before)
my_dataset_train_metadata = MetadataCatalog.get("brain_tumor_train")
dataset_dicts = DatasetCatalog.get("brain_tumor_train")

# Sample 3 images from the dataset
sampled_dicts = random.sample(dataset_dicts, 3)

# Create a figure with 2 rows and 3 columns
fig, axes = plt.subplots(2, 3, figsize=(6, 4))

for idx, d in enumerate(sampled_dicts):
    img = cv2.imread(d["file_name"])
    axes[0, idx].imshow(img[:, :, ::-1])
    axes[0, idx].axis('off')
    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)
    vis = visualizer.draw_dataset_dict(d)
    axes[1, idx].imshow(vis.get_image()[:, :, ::-1])
    axes[1, idx].axis('off')

plt.tight_layout()
plt.savefig("brain_tumor_viz.png", dpi=300)
plt.show()

# Configuration
cfg = get_cfg()

# is there a gpu
if torch.cuda.is_available():
    cfg.MODEL.DEVICE='cuda'
    print('gpu available')
else:
    cfg.MODEL.DEVICE='cpu'
    print('Change runtime to GPU, CUDA is required for AMP training!')

# Configuration
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/retinanet_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("brain_tumor_train",)
cfg.DATASETS.TEST = ("brain_tumor_val",)
cfg.DATALOADER.NUM_WORKERS = os.cpu_count() - 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/retinanet_R_50_FPN_3x.yaml")
cfg.SOLVER.IMS_PER_BATCH = 64
cfg.SOLVER.BASE_LR = 0.01
cfg.SOLVER.MAX_ITER = 2000
cfg.SOLVER.STEPS = (1300, 1700)
cfg.MODEL.RETINANET.NUM_CLASSES = 2
cfg.TEST.EVAL_PERIOD = 150

# Custom Trainer class with hooks for logging
class BrainTumorTrainer(DefaultTrainer):
    @classmethod
    def build_evaluator(cls, cfg, dataset_name, output_folder=None):
        if output_folder is None:
            os.makedirs("coco_eval", exist_ok=True)
            output_folder = "coco_eval"
        return COCOEvaluator(dataset_name, cfg, False, output_folder)

# Train the model
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = BrainTumorTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

# Commented out IPython magic to ensure Python compatibility.
# Look at training curves in tensorboard:
# %load_ext tensorboard
# %tensorboard --logdir output

# Evaluate the model
cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.7
predictor = DefaultPredictor(cfg)
evaluator = COCOEvaluator("brain_tumor_test", cfg, False, output_dir="./output/")
test_loader = build_detection_test_loader(cfg, "brain_tumor_test")
results = inference_on_dataset(predictor.model, test_loader, evaluator)

# # Visualize loss curves and metrics
# from tensorboard.backend.event_processing import event_accumulator
# import glob

# # Find the latest event file
# event_file = max(glob.glob(os.path.join(cfg.OUTPUT_DIR, 'events.out.tfevents.*')), key=os.path.getctime)
# ea = event_accumulator.EventAccumulator(event_file)
# ea.Reload()

# # Extract scalar data
# total_loss = ea.Scalars('total_loss')
# lr = ea.Scalars('lr')

# # Plot total loss
# plt.figure(figsize=(3, 2))
# plt.plot([s.step for s in total_loss], [s.value for s in total_loss])
# plt.title('Total Loss vs. Iterations')
# plt.xlabel('Iterations')
# plt.ylabel('Total Loss')
# plt.savefig('total_loss.png')
# plt.show()

# # Print evaluation results
# print("Evaluation results:", results)

# # Visualize some predictions
# dataset_dicts = DatasetCatalog.get("brain_tumor_test")
# sampled_dicts = random.sample(dataset_dicts, 3)

# # Create a figure with 1 row and 3 columns
# fig, axes = plt.subplots(1, 3, figsize=(6, 2))

# for idx, d in enumerate(sampled_dicts):
#     im = cv2.imread(d["file_name"])
#     outputs = predictor(im)
#     v = Visualizer(im[:, :, ::-1],
#                    metadata=MetadataCatalog.get("brain_tumor_test"),
#                    scale=0.8)
#     v = v.draw_instance_predictions(outputs["instances"].to("cpu"))
#     axes[idx].imshow(v.get_image()[:, :, ::-1])
#     axes[idx].axis('off')
#     axes[idx].set_title(f"Prediction {idx+1}")

# plt.tight_layout()
# plt.savefig("predictions_combined.png", dpi=300)
# plt.show()

# Print evaluation results
print("Evaluation results:", results)

# Visualize some predictions and ground truths
dataset_dicts = DatasetCatalog.get("brain_tumor_test")
sampled_dicts = random.sample(dataset_dicts, 3)

# Create a figure with 1 row and 3 columns
fig, axes = plt.subplots(1, 3, figsize=(20, 10))

for idx, d in enumerate(sampled_dicts):
    im = cv2.imread(d["file_name"])

    # Ground Truth
    v_gt = Visualizer(im[:, :, ::-1],
                      metadata=MetadataCatalog.get("brain_tumor_test"),
                      scale=0.8)
    out_gt = v_gt.draw_dataset_dict(d)

    # Predictions
    outputs = predictor(im)
    v_pred = Visualizer(im[:, :, ::-1],
                        metadata=MetadataCatalog.get("brain_tumor_test"),
                        scale=0.8,
                        instance_mode=ColorMode.IMAGE_BW)
    out_pred = v_pred.draw_instance_predictions(outputs["instances"].to("cpu"))

    # Combine Ground Truth and Prediction on the same subplot
    axes[idx].imshow(out_gt.get_image()[:, :, ::-1])
    axes[idx].imshow(out_pred.get_image()[:, :, ::-1], alpha=0.5)  # Overlay prediction with some transparency
    axes[idx].axis('off')
    axes[idx].set_title(f"Prediction {idx+1}")

plt.tight_layout()
plt.savefig("predictions_combined_with_gt.png", dpi=300)
plt.show()

# # Print evaluation results
# print("Evaluation results:", results)

# # Visualize predictions and ground truths for the entire test set
# dataset_dicts = DatasetCatalog.get("brain_tumor_test")

# # Define a function to visualize a chunk of images
# def visualize_chunk(chunk, chunk_idx):
#     fig, axes = plt.subplots(1, len(chunk), figsize=(20, 10))
#     for idx, d in enumerate(chunk):
#         im = cv2.imread(d["file_name"])

#         # Ground Truth
#         v_gt = Visualizer(im[:, :, ::-1],
#                           metadata=MetadataCatalog.get("brain_tumor_test"),
#                           scale=0.8)
#         out_gt = v_gt.draw_dataset_dict(d)

#         # Predictions
#         outputs = predictor(im)
#         v_pred = Visualizer(im[:, :, ::-1],
#                             metadata=MetadataCatalog.get("brain_tumor_test"),
#                             scale=0.8,
#                             instance_mode=ColorMode.IMAGE_BW)
#         out_pred = v_pred.draw_instance_predictions(outputs["instances"].to("cpu"))

#         # Combine Ground Truth and Prediction on the same subplot
#         axes[idx].imshow(out_gt.get_image()[:, :, ::-1])
#         axes[idx].imshow(out_pred.get_image()[:, :, ::-1], alpha=0.5)  # Overlay prediction with some transparency
#         axes[idx].axis('off')
#         axes[idx].set_title(f"Prediction {chunk_idx*3 + idx + 1}")

#     plt.tight_layout()
#     plt.savefig(f"predictions_combined_with_ground_truth_chunk_{chunk_idx}.png", dpi=300)
#     plt.show()

# # Iterate over the first 45 mri samples in our test dataset in chunks of 3
# chunk_size = 3
# for i in range(0, 45, chunk_size):
#     chunk = dataset_dicts[i:i + chunk_size]
#     visualize_chunk(chunk, i // chunk_size)