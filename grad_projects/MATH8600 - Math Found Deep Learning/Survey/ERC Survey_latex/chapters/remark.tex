In this paper, we survey the best existing approaches for \ac{erc}. The trends revolve around two major architectures: RNN variants (such as GRU), providing the model with a memory of preceding utterances, and transformer-based models, enabling the modeling of inter- and intra-speaker dependencies in utterances. Models like MultiEMO \cite{multiemo} and DialogueTRM \cite{dialoguetrm} that introduced novel fusion mechanisms showed performance improvements. Therefore, future research might benefit from exploring novel methods to maintain contextualized information in uni-modal features and examining the apparent correlation of context within different modalities \cite{multiemo}. The results presented in Table \ref{tab:frameworks} highlight the importance of an attention mechanism in a model's architecture to learn crucial segments of an utterance for the \ac{erc} task.