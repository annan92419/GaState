{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STILL IN PROGRESS... estimated completion date: 04/20/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIKE SHARING DEMAND\n",
    "\n",
    "__Data Fields__ <br>\n",
    "__datetime__ - hourly date + timestamp <br>\n",
    "__season__ -  1 = spring, 2 = summer, 3 = fall, 4 = winter <br> \n",
    "__holiday__ - whether the day is considered a holiday <br>\n",
    "__workingday__ - whether the day is neither a weekend nor holiday <br>\n",
    "__weather__ - 1: Clear, Few clouds, Partly cloudy\n",
    "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog <br>\n",
    "__temp__ - temperature in Celsius <br>\n",
    "__atemp__ - \"feels like\" temperature in Celsius <br>\n",
    "__humidity__ - relative humidity <br>\n",
    "__windspeed__ - wind speed <br>\n",
    "__casual__ - number of non-registered user rentals initiated <br>\n",
    "__registered__ - number of registered user rentals initiated <br>\n",
    "__count__ - number of total rentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inporting useful librabries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mtl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting custom color palettes http://colorbrewer2.org/\n",
    "\n",
    "blue, ach = ['#4393c3'], ['#4d4d4d']\n",
    "div1 = ['#543005','#8c510a','#bf812d','#dfc27d','#f6e8c3','#c7eae5','#80cdc1','#35978f','#01665e','#003c30']\n",
    "div2 = ['#67001f','#b2182b','#d6604d','#f4a582','#fddbc7','#e0e0e0','#bababa','#878787','#4d4d4d','#1a1a1a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "\n",
    "bikedf = pd.read_csv('./dataset/train.csv', sep=r',', parse_dates=['datetime'])\n",
    "bikedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing information about our train dataset\n",
    "\n",
    "bikedf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with datetime column\n",
    "Converting the datetime columns into its components `[year, month, day, dayofweek, hour]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetransform(df):\n",
    "    \"\"\" Function Name: datetransform\n",
    "            This function transforms (and replace) the datetime column of a dataframe\n",
    "            into 5 separate components [year, month, day, dayofweek, hour].\n",
    "    \"\"\"\n",
    "    \n",
    "    dtime_df = pd.DataFrame()\n",
    "    \n",
    "    dtime_df['year'] = df['datetime'].dt.year\n",
    "    dtime_df['month'] = df['datetime'].dt.month\n",
    "    dtime_df['day'] = df['datetime'].dt.day # day on the calendar\n",
    "    dtime_df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "    dtime_df['hour'] = df['datetime'].dt.hour\n",
    "    df.drop(columns='datetime', inplace=True)\n",
    "    \n",
    "    transformed_df = dtime_df.join(df)\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming datetime column in dataset\n",
    "\n",
    "bikedf = datetransform(bikedf)\n",
    "bikedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA EXPLORATION AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the train dataset (to maintain its integrity)\n",
    "eda_df = bikedf.copy()\n",
    "\n",
    "# Description of features\n",
    "cols_description = ['hourly date and timestamp', 'Current Season', 'Day is holiday or not', \n",
    "                    'Day is working day or not', 'Current weather', 'Temperature in Celsius',\n",
    "                    'Feels like temperature in Celsius', 'Relative humidity', 'Wind speed',\n",
    "                    'Number of non-registered user rentals', 'Number of registed user rentals',\n",
    "                    'Total number of rentals']\n",
    "\n",
    "# continuous features\n",
    "cont_cols = eda_df.columns.to_list()[9:-3] #['temp', 'atemp', 'humidity', 'windspeed']\n",
    "print(f'Continuous Features: {cont_cols}')\n",
    "\n",
    "# categorical features\n",
    "cat_cols = eda_df.columns.to_list()[:9] #['year', 'month', 'day', 'dayofweek', 'hour', 'season', 'holiday', 'workingday', 'weather']\n",
    "print(f'Categorical features: {cat_cols}')\n",
    "\n",
    "# target features: casual, registered, count*\n",
    "targets = eda_df.columns.to_list()[-3:]\n",
    "print(f'Target features: {targets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between continuous features and count\n",
    "\n",
    "numcols = cont_cols + targets\n",
    "corr_mat = np.around(eda_df[numcols].corr(), 3)\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(corr_mat, annot=True)\n",
    "plt.show() # interesting features: temp, humidity, casual*, registered*\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between categorical features and count\n",
    "\n",
    "catcols = cat_cols + targets\n",
    "corr_mat = np.around(eda_df[catcols].corr(), 3)\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(corr_mat, annot=True)\n",
    "plt.show() # interesting features: year, hour, season, weather\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting binary* description to actual representation\n",
    "\n",
    "# months = {1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "# weekdays = {0:'Mon', 1:'Tue', 2:'Wed', 3:'Thu', 4:'Fri', 5:'Sat', 6:'Sun'}\n",
    "# seasons = {1:'spring', 2:'summer', 3:'fall', 4:'winter'}\n",
    "# weather = {1:'clear', 2:'cloudy', 3:'light rain', 4:'snowy'}\n",
    "# eda_df['month'] = eda_df['month'].map(months)\n",
    "# eda_df['dayofweek'] = eda_df['dayofweek'].map(weekdays)\n",
    "# eda_df['season'] = eda_df['season'].map(seasons)\n",
    "# eda_df['weather'] = eda_df['weather'].map(weather)\n",
    "\n",
    "# eda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the seasonal statistics of ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "\n",
    "for feature in cont_cols:\n",
    "    print(eda_df.groupby('season')[[feature]].agg(['min','mean','std','max']))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the yearly statistics of ['temp', 'atemp', 'humidity', 'windspeed']\n",
    "\n",
    "for feature in cont_cols:\n",
    "    print(eda_df.groupby('year')[[feature]].agg(['min','mean','std','max']))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of casual, registered, and count\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,8))\n",
    "for i in range(3):\n",
    "    sns.histplot(data=eda_df, bins=15, x=targets[i], ax=axs[i], kde=True)\n",
    "fig.suptitle('Distribution of Number of Bike retals')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of continuous features against target features\n",
    "\n",
    "for feature in cont_cols:\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
    "    sns.scatterplot(data=eda_df, x=feature, y=targets[0], ax=axs[0])\n",
    "    sns.scatterplot(data=eda_df, x=feature, y=targets[1], ax=axs[1], color=ach)\n",
    "    fig.suptitle(f'Scatter plot of {feature.title()}')\n",
    "    plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart of categorical features\n",
    "# exploring the trend of bike rental in both years (2011 and 2012)\n",
    "\n",
    "features_of_interest = ['month', 'hour', 'season', 'weather', 'holiday']\n",
    "for feature in features_of_interest:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n",
    "    sns.barplot(data=eda_df, x=feature, y=targets[0], hue='year', palette=blue+ach, ax=axs[0], errorbar=None)\n",
    "    sns.barplot(data=eda_df, x=feature, y=targets[1], hue='year', palette=blue+ach, ax=axs[1], errorbar=None)\n",
    "    fig.suptitle(f'Trend of bike rentals per {feature.title()}')\n",
    "    plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend of bike sharing during the days of the week when its a holiday\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n",
    "sns.barplot(data=eda_df, x='dayofweek', y=targets[0], hue='holiday', palette=blue+ach, ax=axs[0], errorbar=None)\n",
    "sns.barplot(data=eda_df, x='dayofweek', y=targets[1], hue='holiday', palette=blue+ach, ax=axs[1], errorbar=None)\n",
    "fig.suptitle(f'Trend of bike rentals per {feature.title()}')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend of bike sharing during the days of the week when its a working day\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n",
    "sns.barplot(data=eda_df, x='dayofweek', y=targets[0], hue='workingday', palette=blue+ach, ax=axs[0], errorbar=None)\n",
    "sns.barplot(data=eda_df, x='dayofweek', y=targets[1], hue='workingday', palette=blue+ach, ax=axs[1], errorbar=None)\n",
    "fig.suptitle(f'Trend of bike rentals per {feature.title()}')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bike rentals based on the season and weather\n",
    "\n",
    "group_season_weather = eda_df.groupby(['season','weather'])[['casual','registered']].sum()\n",
    "group_season_weather.plot.bar(figsize=(15,8), color=blue+ach)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating the trend of rent during day of week and time by casual and registered bikers\n",
    "palette = ['#8c510a','#4d4d4d','#542788','#f4a582','#4393c3','#1a9850','#fee08b']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n",
    "sns.lineplot(data=eda_df, x='hour', y=targets[0], linewidth=2.5, palette=palette, hue='dayofweek', ax=axs[0], err_style=None)\n",
    "sns.lineplot(data=eda_df, x='hour', y=targets[1], linewidth=2.5, palette=palette, hue='dayofweek', ax=axs[1], err_style=None)\n",
    "fig.suptitle(f'Hourly bike rental given {feature.title()}')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigatin the variations of the hour the bike were rented with respect to the target features\n",
    "hour = eda_df['hour']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(15,10))\n",
    "sns.boxplot(data=eda_df, x=hour, y=targets[0], ax=axs[0], palette=div2+div1)\n",
    "sns.boxplot(data=eda_df, x=hour, y=targets[1], ax=axs[1], palette=div2+div1)\n",
    "fig.suptitle('Box plot of each hour bike was rented')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Qualitty Report\n",
    "__Continuous Features__ <br>\n",
    "```['temp', 'atemp', 'humidity', 'windspeed']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of continuous features\n",
    "cont_description = ['Temperature in Celsius', 'Feels like temperature in Celsius',\n",
    "                    'Relative humidity', 'Wind speed', 'Number of non-registered user rentals',\n",
    "                    'Number of registed user rentals', 'Total number of rentals']\n",
    "\n",
    "continuous_features_dqr = pd.DataFrame()\n",
    "\n",
    "for idx, feature in enumerate(cont_cols):\n",
    "    cont_dqr = pd.DataFrame()\n",
    "    cont_dqr['Features'] = [feature]\n",
    "    cont_dqr['Description'] = [cont_description[idx]]\n",
    "    cont_dqr['Count'] = [eda_df[feature].shape[0]]\n",
    "    cont_dqr['% of Missing'] = [eda_df[feature].isnull().sum() / eda_df[feature].shape[0]]\n",
    "    cont_dqr['Card.'] = [eda_df[feature].nunique()]\n",
    "    cont_dqr['Min #'] = [eda_df[feature].min()]\n",
    "    cont_dqr['Q1'] = [eda_df[feature].describe()[4]]\n",
    "    cont_dqr['Median'] = [eda_df[feature].median()]\n",
    "    cont_dqr['Q3'] = [eda_df[feature].describe()[6]]\n",
    "    cont_dqr['Max #'] = [eda_df[feature].max()]\n",
    "    cont_dqr['Std. Dev.'] = [eda_df[feature].std()]\n",
    "    continuous_features_dqr = pd.concat([continuous_features_dqr, cont_dqr],\n",
    "                                         axis=0, ignore_index=True)\n",
    "    \n",
    "continuous_features_dqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Categorical Features__ <br>\n",
    "```['year', 'month', 'day', 'dayofweek', 'hour', 'season', 'holiday', 'workingday', 'weather']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of categorical features\n",
    "cat_description = ['Year of rental', 'Month of rental', 'Day of rental', 'Day of week',\n",
    "                   'Hour of day', 'Current Season', 'Day is holiday or not', \n",
    "                    'Day is working day or not', 'Current weather']\n",
    "\n",
    "categorical_features_dqr = pd.DataFrame()\n",
    "\n",
    "for idx, feature in enumerate(cat_cols):\n",
    "    cat_dqr = pd.DataFrame()\n",
    "    cat_dqr['Features'] = [feature]\n",
    "    cat_dqr['Description'] = [cat_description[idx]]\n",
    "    cat_dqr['Count'] = [eda_df[feature].shape[0]]\n",
    "    cat_dqr['% of Missing'] = [eda_df[feature].isnull().sum() / eda_df[feature].shape[0]]\n",
    "    cat_dqr['Card.'] = [eda_df[feature].nunique()]\n",
    "    cat_dqr['1st Mode'] = [eda_df[feature].mode(dropna=True)[0]]\n",
    "    cat_dqr['1st Mode Freq.'] = [eda_df[eda_df[feature] == cat_dqr['1st Mode'][0]].shape[0]]\n",
    "    cat_dqr['1st Mode %'] = np.around(cat_dqr['1st Mode Freq.'] / cat_dqr['Count'] * 100, 2)\n",
    "    cat_dqr['2nd Mode'] = [eda_df[eda_df[feature] != cat_dqr['1st Mode'][0]][feature].mode(dropna=True)[0]]\n",
    "    cat_dqr['2nd Mode Freq.'] = [eda_df[eda_df[feature] == cat_dqr['2nd Mode'][0]].shape[0]]\n",
    "    cat_dqr['2nd Mode %'] = np.around(cat_dqr['2nd Mode Freq.'] / cat_dqr['Count'] * 100, 2)\n",
    "    categorical_features_dqr = pd.concat([categorical_features_dqr, cat_dqr],\n",
    "                                         axis=0, ignore_index=True)\n",
    "    \n",
    "categorical_features_dqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Missing Values and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Missing Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values in the eda dataset\n",
    "eda_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outliers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating and removing potential outliers in the dataset\n",
    "\n",
    "def remove_outlier(df):\n",
    "    \"\"\" Function Name: remove outliers\n",
    "            This function takes in a dataframe and removes\n",
    "            top and bottom k% outliers in count and also\n",
    "            take out dangerous windspeed (>29mph)\n",
    "    \"\"\"\n",
    "    # At 30mph or, the wind makes cycling quite difficult,\n",
    "    # even for the more experienced cyclist.\n",
    "    windtresh  = 29\n",
    "    tresh = df['windspeed'] > windtresh\n",
    "    df = df.drop(index=df[tresh].index)\n",
    "\n",
    "    k = 2\n",
    "    lower = df['count'] < df['count'].quantile(k/100)\n",
    "    upper = df['count'] > df['count'].quantile(1-k/100)\n",
    "    df = df.drop(index=df[lower].index)\n",
    "    df = df.drop(index=df[upper].index)\n",
    "        \n",
    "    return df\n",
    "\n",
    "outlier_removed = remove_outlier(eda_df)\n",
    "print(eda_df.shape, outlier_removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" UNCOMMENT ME \"\"\"\n",
    "\n",
    "# # visualizing the change in distribution for the continuous columns\n",
    "\n",
    "# for feature in numcols:\n",
    "#     fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
    "#     sns.histplot(data=eda_df, x=feature, bins=20, kde=True, ax=axs[0])\n",
    "#     sns.histplot(data=outlier_removed, x=feature, bins=20, kde=True, ax=axs[1])\n",
    "#     plt.show()\n",
    "# plt.clf()\n",
    "\n",
    "\n",
    "# # visualizing the change in variation for the categorical columns\n",
    "\n",
    "# for feature in cat_cols:\n",
    "#     fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,8))\n",
    "#     sns.boxplot(data=eda_df, x=feature, y=targets[2], ax=axs[0], palette=div2+div1)\n",
    "#     sns.boxplot(data=outlier_removed, x=feature, y=targets[2], ax=axs[1], palette=div2+div1)\n",
    "#     plt.show()\n",
    "# plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Continuours Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, cols):\n",
    "    \"\"\" Function Name: Normalize\n",
    "            This function takes a dataframe and specified numerical\n",
    "            columns and transforms them between [0, 1]\n",
    "    \"\"\"\n",
    "    for feature in cols:\n",
    "        minval, maxval = df[feature].min(), df[feature].max()\n",
    "        df[feature] = ( df[feature] - minval ) / ( maxval - minval )\n",
    "\n",
    "    return df\n",
    "\n",
    "eda_df = normalize(outlier_removed, cont_cols)\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Selection__ <br>\n",
    "`keep features: {atemp, humidity, year, hour, season, workingday, weather}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['year', 'hour', 'season', 'workingday', 'weather', 'atemp', 'humidity', 'count']\n",
    "eda_df = eda_df[keep]\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Transformation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies for categorical features\n",
    "\n",
    "dummy = ['year', 'hour', 'season', 'workingday', 'weather']\n",
    "eda_df[dummy] = eda_df[dummy].astype('object')\n",
    "eda_df = pd.get_dummies(eda_df, columns=dummy, drop_first=True)\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning the target feature into 4 bins (1. using the iqr | 2. using equal width binning)\n",
    "# 1: few; 2: okay; 3: enough; 4: a_lot\n",
    "\n",
    "eda_iqr = eda_df.copy()\n",
    "eda_bin = eda_df.copy()\n",
    "\n",
    "def bin_target(df, target='count'):\n",
    "    temp = df[target].to_numpy()\n",
    "    new = []\n",
    "    lower, upper = np.min(temp), np.max(temp)\n",
    "    inc = (upper - lower) / 4\n",
    "\n",
    "    for val in temp:\n",
    "        if val <= inc :\n",
    "            new.append(1)\n",
    "        elif val <= 2*inc :\n",
    "            new.append(2)\n",
    "        elif val <= 3*inc :\n",
    "            new.append(3)\n",
    "        else:\n",
    "            new.append(4)\n",
    "    df[target] = new\n",
    "\n",
    "    return df\n",
    "\n",
    "eda_bin = bin_target(eda_bin, 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL SELECTION AND EVALUATION\n",
    "Data sets used: `eda_df, eda_bin, eda_iqr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inporting useful librabries and test data set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, ConfusionMatrixDisplay, confusion_matrix, r2_score, mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = eda_df.drop(columns='count')\n",
    "y = eda_df['count']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=.70, random_state=11)\n",
    "print(Xtest.shape, Xtrain.shape)\n",
    "\n",
    "for n in range(15,21):\n",
    "    dtrmdl = DecisionTreeRegressor(criterion='squared_error' , max_depth=n, random_state=11)\n",
    "    dtrmdl.fit(Xtrain, ytrain)\n",
    "    print(n, ':', dtrmdl.score(Xtest, ytest), dtrmdl.score(Xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = eda_bin.drop(columns='count')\n",
    "y = eda_bin['count']\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=.70, random_state=11)\n",
    "print(Xtest.shape, Xtrain.shape)\n",
    "\n",
    "for n in range(15,21):\n",
    "    dtclf = DecisionTreeClassifier(criterion='entropy', max_depth=n, random_state=11)\n",
    "    dtclf.fit(Xtrain, ytrain)\n",
    "    ypred = dtclf.predict(Xtest)\n",
    "    print(n, ':', accuracy_score(ytest, ypred))\n",
    "\n",
    "# confusion matrix\n",
    "conf_metrix = confusion_matrix(ytest, ypred)\n",
    "conf_metrix_display = ConfusionMatrixDisplay(confusion_matrix=conf_metrix, display_labels=['few', 'okay', 'enough', 'alot'])\n",
    "conf_metrix_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
